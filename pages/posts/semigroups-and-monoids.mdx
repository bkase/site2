import Page from '@reason/pages/Posts.bs'; export default Page;

export const meta = {
  date: 1581841641579,
  description: "Semigroups and monoids are the two algebraic structures that are the most useful to the working engineer. Discovering the underlying algebraic structures in our APIs give rise to a minimally complex and maximally expressive interface, and the shared vocabulary of these terms give rise to productive teams. In this post, all code examples will be presented in OCaml, ReasonML, Haskell, and Swift."
};

# Semigroups and Monoids

If you ask someone who has interacted with me in the last five years to describe me, they may say: Brandon loves monoids. I do love monoids, and although I do think there are enough existing materials on the subject on the internet, I figured I should probably add my take to the mix.[^1]

As engineers, we study algebraic structures (like semigroups and monoids) for a few reasons:[^2]

1. Mathematics gives us an objective solution to "clean code" and API design &mdash; discovering the algebraic structure underlying the problem gives rise to a minimally complex and maximally expressive interface.
2. These structures give names to incredibly abstract notions. Notions that we otherwise, as humans, would have a hard time discussing. When something has a name, our brains can reason about them. Shared vocabulary means more productivity for teams. Moreover, using these proper names introduces a ~hundred years of mathematics and computer science content for further study.

Semigroups and Monoids are the "20%" of algebraic objects that get you "80%" of the power. These are a functional programmer's basic building blocks: The ability to detect, digest, and discover them levels you up as an engineer!

Since I want this post to be maximally relevant to the audiences I think I'll reach, I'm preparing all code examples in OCaml, ReasonML, Haskell, and Swift throughout this post.

## Algebraic structures in programs

Algebraic structures in typed programming languages are defined by signatures/protocols/type-classes/interfaces. Instances of these structures are declared by conformances/instances of these signatures. In addition to those instances that don't type-check, the set of instances is further restricted by *laws* or equivalences between two programs which should always be true. For example, a structure with a *commutativity* law aka $\forall x,y. x \oplus y = y \oplus x$[^3] permits an implementation for $\oplus$ for integer multiplication but rejects matrix multiplication.[^4]

## Semigroup

A semigroup is a type coupled with a closed[^5] binary[^6] associative operation that acts on that type, $(T, \oplus)$. Addition over integers, $(Int, +)$, multiplication over integers, $(Int, \times)$, and concat over non-empty lists, $(NonEmptyList, ++)$ are all semigroups. Likewise for [cache composition](https://www.youtube.com/watch?v=8uqXuEZLyUU) and [sequencing animations](https://www.youtube.com/watch?v=xAFawAKjLfA).

The associativity law demands $\forall x, y, z. (x \oplus y) \oplus z = x \oplus (y \oplus z)$. This is the case for all the examples shown above. A counter-example for illustration purposes: Subtraction over integers, $(Int, -)$. Proof: Take $x=1,y=2,z=3$, $(1 - 2) - 3$ evaluates to $-4$, but $1 - (2-3)$ evaluates to $+2$!

Since it's hard to type $\oplus$ in our programming development environments, we typically use `<>` to denote this operation. If the operation happens to be commutative[^7] as well, we use `+` -- though in ML langs we need to make an exception.

<MultiCodeBlock>

```ocaml
module type Semigroup = sig
  type t

  (* We don't use <> in the ML langs because <> is traditionally "is not equal" *)
  val (+) : t -> t -> t
end
```

```haskell
-- You can find this in Data.Semigroup
class Semigroup a where
  (<>) :: a -> a -> a
```

```swift
protocol Semigroup {
  static func <>(a: Self, b: Self) -> Self
}
```

</MultiCodeBlock>

Instances of semigroups are instances of the corresponding signature/protocol/type class:

<MultiCodeBlock>

```ocaml
module Sum : Semigroup = struct
  type t = int

  let (+) = Int.(+)
end
```

```haskell
newtype Sum = Sum Int
instance Semigroup Sum where
  (Sum x) <> (Sum y) = Sum (x + y)
```

```swift
struct Sum { let v: Int }
extension Sum : Semigroup {
  func <>(a: Sum, b: Sum) -> Sum {
    return Sum(a.v + b.v)
  }
}
```

</MultiCodeBlock>

Algebraic properties give us magical powers. Associativity gives the programmer and the runtime the freedom to re-associate chunks of work.

As programmers, we get to choose grouping together operations in whichever way we feel is most appropriate for the situation.

<MultiCodeBlock>

```ocaml
let xy = x + y in
let all = xy + z in
(* or *)
let all = x + y + z in
()
(* ... *)
```

```haskell
xy = x <> y
all = xy <> z
-- or
all = x <> y <> z
```

```swift
let xy = x <> y
let all = xy <> z
// or
let all = x <> y <> z
```

</MultiCodeBlock>

On the other hand, the machine can choose to schedule this work whenever it
pleases. As a consequence, semigroups can hook into many pieces of machinery in
other libraries and frameworks, for example, we can use the associativity to imbue parallelism into our work for free!

<MultiCodeBlock>

```ocaml
(* Work to do: x + y + z + w *)
let xy = x + y in (* thread1 *)
let zw = z + w in (* thread2 *)
xy + zw
```

```haskell
-- Work to do: x + y + z + w
let xy = x <> y in -- thread1
let zw = z <> w in -- thread2
xy <> zw
```

```swift
// Work to do: x + y + z + w
let xy = x <> y // thread1
let zw = z <> w // thread2
xy <> zw
```

</MultiCodeBlock>

Associativity is a very common property, so whenever you find yourself with a binary operation &mdash; it's worth asking: Is this associative &mdash; is this a semigroup?

## Monoids

A monoid extends semigroups with an identity, $\epsilon$. So a monoid is a type, a closed binary associative operation, and an identity: $(T, \oplus, \epsilon)$. Many of the examples above for semigroups are also monoids: Addition of integers uses $0$ as an identity. Multiplication of integers' identity is $1$. We can construct an identity cache to make cache composition a monoid.

To be a valid identity, the following law must hold: $\forall x. x \oplus \epsilon = \epsilon \oplus x = x$, in other words, combining with the identity on the left or the right is the same as doing nothing at all. There is no $\epsilon$ which obeys that law that makes $(NonEmptyList, ++, \epsilon)$ a monoid. However, $(List, ++, [])$ is a monoid because concatenating the empty list on the left and right over any other list is the same as not concatenating at all.

Since it's hard to type $\epsilon$ in our programming development environments, we typically use `empty` to denote this operation.

<MultiCodeBlock>

```ocaml
module type Monoid = sig
  include Semigroup
  val empty : t
end
```

```haskell
class Semigroup a => Monoid a where
  mempty :: a
```

```swift
protocol Monoid : Semigroup {
  static var empty : Self { get }
}
```

</MultiCodeBlock>

An example instance:

<MultiCodeBlock>

```ocaml
module ListM : Monoid = struct
  include ListS (* a semigroup *)
  let empty = []
end
```

```haskell
newtype ListM a = ListM (List a)
instance Semigroup (ListM a) -- ...
instance Monoid (ListM a) where
  empty = ListM []
```

```swift
struct ListM<A> { let v: [A] }
extension ListM : Semigroup { /* ... */ }
extension ListM : Monoid {
  static var empty: ListM { return [] }
}
```

</MultiCodeBlock>

The power of an identity is that there always exists a default or a known empty. Monoids let us "drop the option":

<MultiCodeBlock>

```ocaml
let annoyinglyNeedsOption =
  if computation() then Some (x + y) else None
(* to *)
let expressiveNoNeedOption =
  if computation() then x + y else M.empty
```

```haskell
annoyinglyNeedsMaybe :: Maybe a
annoyinglyNeedsMaybe =
  if computation then Just (x <> y) else None
-- to
expressiveNoNeedMaybe :: Monoid a => a
expressiveNoNeedMaybe x =
  if computation then x else mempty
```

```swift
func annoyinglyNeedMaybe<M>() -> M? {
  return computation ? x <> y : nil
}
// to
func expressiveNoNeedMaybe<M: Monoid>() -> M {
  return computation ? x <> y : M.empty
}
```

</MultiCodeBlock>

Monoids are the building blocks of composition. And composition leads to clean, simple, and expressive code. Moreover, when you and your colleagues can speak about these abstract notions concretely you get a huge productivity boost!

Thank you [Tiziano Coroneo](https://twitter.com/TizianoCoroneo), [@\_lksz\_](https://twitter.com/_lksz_), [Kaan Dedeoglu](https://twitter.com/kaandedeoglu), [Avery Morin](https://twitter.com/_schmavery), and [Hillel Wayne](https://twitter.com/Hillelogram) for pointing out some mistakes in earlier versions of this post!

[^1]: You can also choose to consume this blog post [in video form](https://www.youtube.com/watch?v=6z9QjDUKkCs) with Swift as the programming language substrate.
[^2]: Okay, for full disclosure, I have to admit that intellectual self-indulgence also drives me to dig deep into this sort of thing. But trust me, semigroups and monoids are extremely useful!
[^3]: The upside-down `A`, $\forall$, reads as "for all" -- this whole statement also reads as: For all choices of $x$ and $y$, combining $x$ and $y$ is the same as combining $y$ and $x$ &mdash; a formally precise way of saying "the order that we combine doesn't matter".
[^4]: Matrix multiplication $M_1 * M_2$ means something different than $M_2 * M_1$ &mdash; see [wikipedia](https://en.wikipedia.org/wiki/Matrix_multiplication) for more.
[^5]: Closed in this context means that the operation always returns an element of this same type, $\forall x: T, y: T. (x + y): T$, the operation never diverges with an infinite loop or throws an exception.
[^6]: A binary operation is one which acts on two elements: $f(x,y)$ or $x \oplus y$.
[^7]: Commutativity allows you to rearrange terms, the order of their position doesn't affect the outcome $\forall x, y. x + y = y + x$.

